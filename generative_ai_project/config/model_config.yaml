# config/model_config.yaml

# UniBS Cluster Configuration
unibs_cluster:
  base_url: "https://gpustack.ing.unibs.it/v1"
  # models: List of models supported by the cluster (for reference)
  # - phi4-mini
  # - phi4
  # - llama3.2
  # - gpt-oss
  # - qwen3
  # - granite3.3
  # - gemma3

# Active Model for standard analysis (single model mode)
active_model: "phi4-mini"

# List the models to be used for the ensemble/consensus pipeline.
# If this list is active, the pipeline will run all these models and compute agreement.
ensemble_models:
  - "phi4-mini"
  - "llama3.2"
  - "gemma3"  

llm_parameters:
  temperature: 0.8        
  top_p: 0.95            
  max_tokens: 1024       
  frequency_penalty: 0   
  presence_penalty: 0    

paths:
  raw_data: "data/raw/messages.json"
  chat_index_url: "https://raw.githubusercontent.com/Casualtek/Ransomchats/main/chat_index.json"
  base_raw_url: "https://raw.githubusercontent.com/Casualtek/Ransomchats/main/"

processing:
  max_workers: 4
  max_prompt_chars: 10000
